{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('dsu-mlpp': pipenv)",
   "metadata": {
    "interpreter": {
     "hash": "cc067fc62129187a5fd73fcbb1d860a65d48f251b5425e03f4f70aa6acab540c"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Determine the frequency of duplicate scores across several osu random dump\n",
    "**Contributors:** Victor Lin\n",
    "\n",
    "**Achievement:** The frequency of duplicate scores (scores from the same player, beatmap, and mods) was found to be 778, or ~.00078% of the 10M scores present across all dumps. Duplicates can be safely ignored for the data cleaning process."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Introduction\n",
    "Isolated osu random dumps contain 10k unique players. However, there can be player crossover *between* dumps. This leads to the possibility of duplicate scores, where a player in an older dump updates their score for a particular beatmap+mod, resulting in a repeat in the new dump.\n",
    "\n",
    "The SQL pipeline to pinpoint the frequency of these duplicates falls under 2 steps:\n",
    "\n",
    "1. Reduce Player Search Space\n",
    "\n",
    "2. Calculate Duplicate Frequency"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymysql\n",
    "import pandas as pd\n",
    "from exploration.config import sql_inst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_dump_titles = [\n",
    "    \"osu_random_2020_08\",\n",
    "    \"osu_random_2020_09\",\n",
    "    \"osu_random_2020_10\",\n",
    "    \"osu_random_2020_11\",\n",
    "    \"osu_random_2020_12\",\n",
    "    \"osu_random_2021_01\"\n",
    "]"
   ]
  },
  {
   "source": [
    "## 1) Reduce Search Space\n",
    "Union all osu_user_stats tables to identify only the players with crossover. No need to search other players, as they cannot have duplicates."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_repeat_users(dump_titles):\n",
    "    template = \"(SELECT user_id FROM {}.osu_user_stats)\".format\n",
    "    QUERY_UNION_USER_ID = '\\nUNION ALL\\n'.join(map(template, random_dump_titles))\n",
    "\n",
    "    with sql_inst.cursor() as cursor:\n",
    "        cursor.execute(\n",
    "            f\"\"\"\n",
    "            SELECT user_id\n",
    "            FROM (\n",
    "                {QUERY_UNION_USER_ID}\n",
    "            )as USERS_INCLUDING_DUPE\n",
    "            GROUP BY user_id\n",
    "            HAVING COUNT(*) > 1\n",
    "            ORDER BY COUNT(*) DESC \n",
    "            \"\"\"\n",
    "        )\n",
    "\n",
    "        return tuple(row[0] for row in cursor)\n",
    "\n",
    "REPEAT_USERS_TUPLE = find_repeat_users(random_dump_titles)"
   ]
  },
  {
   "source": [
    "## 2) Frequency Calculation\n",
    "Only for osu highscores from the players identified, group scores by unique (player, beatmap, mod) combinations. Accumulate the frequency of groups > 1 (aka duplicate scores)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   num_dumps  freq\n",
       "0          2   778"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>num_dumps</th>\n      <th>freq</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2</td>\n      <td>778</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "def get_repeat_freq_table(repeat_users):\n",
    "    template = (\"\"\"\n",
    "    SELECT score_id, user_id, beatmap_id, enabled_mods\n",
    "            FROM {}.osu_scores_high\n",
    "            WHERE\n",
    "            user_id IN \"\"\" + str(REPEAT_USERS_TUPLE)\n",
    "    ).format\n",
    "\n",
    "    QUERY_USERS_UNION_SCORES = '\\nUNION\\n'.join(map(template, random_dump_titles))\n",
    "\n",
    "    query = f\"\"\"\n",
    "            SELECT B.num_dumps, COUNT(*) as freq FROM (\n",
    "                SELECT COUNT(*) as num_dumps FROM (\n",
    "                    {QUERY_USERS_UNION_SCORES}\n",
    "                ) as A\n",
    "                GROUP BY A.user_id, A.beatmap_id, A.enabled_mods\n",
    "            ) as B\n",
    "            WHERE B.num_dumps > 1\n",
    "            GROUP BY B.num_dumps\n",
    "            \"\"\"\n",
    "\n",
    "    return pd.read_sql(query, sql_inst)\n",
    "\n",
    "get_repeat_freq_table(REPEAT_USERS_TUPLE)"
   ]
  },
  {
   "source": [
    "## Interpretation\n",
    "The above table shows score repeats for 2 dumps were found 778 times out of all 6 osu random dumps. There were no scores that were found across 3 or more dumps. This makes sense, as the probability of each additional dump update should exponentially decreases."
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}